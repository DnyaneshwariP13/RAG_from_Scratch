{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")\n",
    "GEMINI_API_KEY=os.getenv(\"GEMINI_API_KEY\")\n",
    "genai.Client(api_key=GEMINI_API_KEY)\n",
    "#Video url\n",
    "YOUTUBE_VIDEO=\"https://www.youtube.com/watch?v=qU3fmidNbJE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Setup\n",
    "#defining LLM \n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "model=ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo\")\n",
    "gemini_model=ChatGoogleGenerativeAI(google_api_key=GEMINI_API_KEY,\n",
    "    model=\"gemini-2.0-flash-001\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The Los Angeles Dodgers won the World Series in 2020, which was during the COVID-19 pandemic.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-001', 'safety_ratings': []}, id='run-d0899f43-8fc0-4687-9f94-aee80bc67877-0', usage_metadata={'input_tokens': 15, 'output_tokens': 26, 'total_tokens': 41, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing model vy asking simple question\n",
    "gemini_model.invoke(\"What MLB team won the World Series during the COVID-19 pandemic?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Los Angeles Dodgers won the World Series in 2020, which was during the COVID-19 pandemic.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we are using simple StrOutputParser to extract the answer as a string\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser=StrOutputParser()\n",
    "chain=gemini_model | parser\n",
    "chain.invoke(\"hat MLB team won the World Series during the COVID-19 pandemic?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: \\nAnswer the question based on context below. If you can\\'t answer the question, reply \"I don\\'t know.\".\\n\\nContext:Dnya\\'s sister is Praju\\nQuestion:Who is Dnya\\'s sister?\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "template=\"\"\"\n",
    "Answer the question based on context below. If you can't answer the question, reply \"I don't know.\".\n",
    "\n",
    "Context:{context}\n",
    "Question:{question}\n",
    "\"\"\"\n",
    "\n",
    "prompt=ChatPromptTemplate.from_template(template)\n",
    "prompt.format(context=\"Dnya's sister is Praju\",question=\"Who is Dnya's sister?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Praju'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain=prompt | gemini_model | parser\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"context\":\"Dnya's sister is Praju\",\n",
    "        \"question\":\"Who is Dnya's sister?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_prompt=ChatPromptTemplate.from_template(\n",
    "    \"Translate {answer} to {language}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The most accurate translation of \"Dnya has two sisters: Praju and Vaish\" to Marathi is:\\n\\n**ज्ञाला दोन बहिणी आहेत: प्राजू आणि वैश.**\\n\\nHere\\'s a breakdown:\\n\\n*   **ज्ञाला (Dnyala):** \"To Dnya\" (dative case, indicating possession)\\n*   **दोन (don):** Two\\n*   **बहिणी (bahini):** Sisters\\n*   **आहेत (aahet):** Are/have\\n*   **प्राजू (Praju):** Praju\\n*   **आणि (aani):** And\\n*   **वैश (Vaish):** Vaish\\n\\nTherefore, the complete sentence means \"Dnya has two sisters: Praju and Vaish.\"'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "translation_chain=(\n",
    "    {\"answer\":chain, \"language\":itemgetter(\"language\")} | translation_prompt | gemini_model | parser\n",
    ")\n",
    "\n",
    "translation_chain.invoke(\n",
    "    {\n",
    "        \"context\": \"Dnya's sister is Praju and one more sister Vaish.\",\n",
    "        \"question\": \"How many sisters does Dnya have? and what are their names?\",\n",
    "        \"language\": \"Marathi\",\n",
    "    }\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transcribing YouTube Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/*\\n# if transcribe file not created \\nif not os.path.exists(\"transcription.txt\"):\\n    youtube=YouTube(YOUTUBE_VIDEO)\\n    audio=youtube.streams.filter(only_audio=True).first()\\n\\n    #loading base model, not most accurate but its fast\\n    whisper_model=whisper.load_model(\"base\")\\n\\n    with tempfile.TemporaryDirectory() as tmpdir:\\n        file=audio.download(output_path=tmpdir)\\n        transcription=whisper_model.transcribe(file,fp16=False)[\"text\"].strip()\\n\\n        with open(\"transcription.txt\",\"w\") as file:\\n            file.write(transcription)\\n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''/*\n",
    "# if transcribe file not created \n",
    "if not os.path.exists(\"transcription.txt\"):\n",
    "    youtube=YouTube(YOUTUBE_VIDEO)\n",
    "    audio=youtube.streams.filter(only_audio=True).first()\n",
    "\n",
    "    #loading base model, not most accurate but its fast\n",
    "    whisper_model=whisper.load_model(\"base\")\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        file=audio.download(output_path=tmpdir)\n",
    "        transcription=whisper_model.transcribe(file,fp16=False)[\"text\"].strip()\n",
    "\n",
    "        with open(\"transcription.txt\",\"w\") as file:\n",
    "            file.write(transcription)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcript saved to transcript.txt\n"
     ]
    }
   ],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "def get_video_id(url):\n",
    "    return parse_qs(urlparse(url).query).get(\"v\", [None])[0]\n",
    "\n",
    "# Step 1: Set the video URL\n",
    "url = \"https://www.youtube.com/watch?v=FwOTs4UxQS4\"  # replace with actual ID\n",
    "\n",
    "# Step 2: Get transcript text\n",
    "video_id = get_video_id(url)\n",
    "transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "text = \" \".join([t[\"text\"] for t in transcript])\n",
    "\n",
    "# Step 3: Save to a .txt file\n",
    "filename = f\"transcript.txt\"\n",
    "with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(text)\n",
    "\n",
    "print(f\"Transcript saved to {filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ai ai ai ai ai ai you know more agentic agentic capabilities an AI agent agents agentic workflows agents agents agent agent agent agent agentic all right most explanations of AI agents is either too technical or too basic this video is meant for people like myself you have zero technical background but you use AI tools regularly and you want to learn just enough about AI agents to see how it affects you in this video we'll follow a simple one two three learning path by building on concepts you already understand like chatbt and then moving on to AI workflows and then finally AI agents all the while using examples you will actually encounter in real life and believe me when I tell you those intimidating terms you see everywhere like rag rag or react they're a lot simpler than you think let's get started kicking things off at level one large language models popular AI chatbots like CHBT Google Gemini and Claude are applications built on top of large language models LLMs and they're fanta\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"transcript.txt\") as file:\n",
    "    transcription = file.read()\n",
    "\n",
    "transcription[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    chain.invoke(\n",
    "        {\n",
    "        \"context\": transcript,\n",
    "        \"question\": \"What is AI agent?\"    \n",
    "        }\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'transcript.txt'}, page_content='ai ai ai ai ai ai you know more agentic agentic capabilities an AI agent agents agentic workflows agents agents agent agent agent agent agentic all right most explanations of AI agents is either too technical or too basic this video is meant for people like myself you have zero technical background but you use AI tools regularly and you want to learn just enough about AI agents to see how it affects you in this video we\\'ll follow a simple one two three learning path by building on concepts you already understand like chatbt and then moving on to AI workflows and then finally AI agents all the while using examples you will actually encounter in real life and believe me when I tell you those intimidating terms you see everywhere like rag rag or react they\\'re a lot simpler than you think let\\'s get started kicking things off at level one large language models popular AI chatbots like CHBT Google Gemini and Claude are applications built on top of large language models LLMs and they\\'re fantastic at generating and editing text here\\'s a simple visualization you the human provides an input and the LLM produces an output based on its training data for example if I were to ask Chachi BT to draft an email requesting a coffee chat my prompt is the input and the resulting email that\\'s way more polite than I would ever be in real life is the output so far so good right simple stuff but what if I asked Chachi BT when my next coffee chat is even without seeing the response both you and I know Chachi PT is gonna fail because it doesn\\'t know that information it doesn\\'t have access to my calendar this highlights two key traits of large language models first despite being trained on vast amounts of data they have limited knowledge of proprietary information like our personal information or internal company data second LLMs are passive they wait for our prompt and then respond right keep these two traits in mind moving forward moving to level two AI workflows let\\'s build on our example what if I a human told the LM \"Every time I ask about a personal event perform a search query and fetch data from my Google calendar before providing a response.\" With this logic implemented the next time I ask \"When is my coffee chat with Elon Husky?\" I\\'ll get the correct answer because the LLM will now first go into my Google calendar to find that information but here\\'s where it gets tricky what if my next follow-up question is \"What will the weather be like that day?\" The LM will now fail at answering the query because the path we told the LM to follow is to always search my Google calendar which does not have information about the weather this is a fundamental trait of AI workflows they can only follow predefined paths set by humans and if you want to get technical this path is also called the control logic pushing my example further what if I added more steps into the workflow by allowing the LM to access the weather via an API and then just for fun use a text to audio model to speak the answer the weather forecast for seeing Elon Husky is sunny with a chance of being a good boy here\\'s the thing no matter how many steps we add this is still just an AI workflow even if there were hundreds or thousands of steps if a human is the decision maker there is no AI agent involvement pro tip: retrieval augmented generation or rag is a fancy term that\\'s thrown around a lot in simple terms rag is a process that helps AI models look things up before they answer like accessing my calendar or the weather service essentially Rag is just a type of AI workflow by the way I have a free AI toolkit that cuts through the noise and helps you master essential AI tools and workflows i\\'ll leave a link to that down below here\\'s a real world example following Helena Louu\\'s amazing tutorial I created a simple AI workflow using make.com here you can see that first I\\'m using Google Sheets to do something specifically I\\'m compiling links to news articles in a Google sheet and this is that Google sheet second I\\'m using Perplexity to summarize those news articles then using Claude and using a prompt that I wrote I\\'m asking Claude to draft a LinkedIn and Instagram post finally I can schedule this to run automatically every day at 8 a.m as you can see this is an AI workflow because it follows a predefined path set by me step one you do this step two you do this step three you do this and finally remember to run daily at 8 am one last thing if I test this workflow and I don\\'t like the final output of the LinkedIn post for example as you can see right here uh it\\'s not funny enough and I\\'m naturally hilarious right i\\'d have to manually go back and rewrite the prompt for Claude okay and this trial and error iteration is currently being done by me a human so keep that in mind moving forward all right level three AI agents continuing the make.com example let\\'s break down what I\\'ve been doing so far as the human decision maker with the goal of creating social media posts based off of news articles I need to do two things first reason or think about the best approach i need to first compile the news articles then summarize them then write the final posts second take action using tools i need to find and link to those news articles in Google Sheets use Perplexity for real-time summarization and then claw for copyrightiting so and this is the most important sentence in this entire video the one massive change that has to happen in order for this AI workflow to become an AI agent is for me the human decision maker to be replaced by an LLM in other words the AI agent must reason what\\'s the most efficient way to compile these news articles should I copy and paste each article into a word document no it\\'s probably easier to compile links to those articles and then use another tool to fetch the data yes that makes more sense the AI agent must act aka do things via tools should I use Microsoft Word to compile links no inserting links directly into rows is way more efficient what about Excel m so the user has already connected their Google account with make.com so Google Sheets is a better option pro tip because of this the most common configuration for AI agents is the react framework all AI agents must reason and act so react sounds simple once we break it down right a third key trait of AI agents is their ability to iterate remember when I had to manually rewrite the prompt to make the LinkedIn post funnier i the human probably need to repeat this iterative process a few times to get something I\\'m happy with right an AI agent will be able to do the same thing autonomously in our example the AI agent would autonomously add in another LM to critique its own output okay I\\'ve drafted V1 of a LinkedIn post how do I make sure it\\'s good oh I know i\\'ll add another step where an LM will critique the post based on LinkedIn best practices and let\\'s repeat this until the best practices criteria are all met and after a few cycles of that we have the final output that was a hypothetical example so let\\'s move on to a real world AI agent example andrew is a preeeminent figure in AI and he created this demo website that illustrates how an AI agent works i\\'ll link the full video down below but when I search for a keyword like skier enter the AI vision agent in the background is first reasoning what a skier looks like a person on skis going really fast in snow for example right i\\'m not sure and then it\\'s acting by looking at clips in video footage trying to identify what it thinks a skier is indexing that clip and then returning that clip to us although this might not feel impressive remember that an AI agent did all that instead of a human reviewing the footage beforehand manually identifying the skier and adding tags like skier mountain ski snow the programming is obviously a lot more technical and complicated than what we see in the front end but that\\'s the point of this demo right the average user like myself wants a simple app that just works without me having to understand what\\'s going on in the back end speaking of examples I\\'m also building my very own basic AI agent using Nan so let me know in the comments what type of AI agent you\\'d like me to make a tutorial on next to wrap up here\\'s a simplified visualization of the three levels we covered today level one we provide an input and the LM responds with an output easy level two for AI workflows we provide an input and tell the LM to follow a predefined path that may involve in retrieving information from external tools the key trait here is that the human programs a path for LM to follow level three the AI agent receives a goal and the LM performs reasoning to determine how best to achieve the goal takes action using tools to produce an interim result observes that interim result and decides whether iterations are required and produces a final output that achieves the initial goal the key trait here is that the LLM is a decision maker in the workflow if you found this helpful you might want to learn how to build a prompts database in Notion see you on the next video in the meantime have a great one')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader=TextLoader(\"transcript.txt\")\n",
    "text_documents=loader.load()\n",
    "text_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=40)\n",
    "text_splitter.split_documents(text_documents)[:5]\n",
    "documents = text_splitter.split_documents(text_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding length: 768\n",
      "[0.0234909038990736, -0.007969883270561695, -0.060786258429288864, -0.0255004670470953, -0.00024231472343672067, 0.00904453732073307, -0.0014154528034850955, -0.029917960986495018, 0.01235028076916933, 0.030848467722535133]\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embeddings=GoogleGenerativeAIEmbeddings(google_api_key=GEMINI_API_KEY,model=\"models/text-embedding-004\")\n",
    "embedded_query=embeddings.embed_query(\"Who is Dnya's sister?\")\n",
    "\n",
    "print(f\"Embedding length: {len(embedded_query)}\")\n",
    "print(embedded_query[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = embeddings.embed_query(\"DNya's sister is Praju\")\n",
    "sentence2 = embeddings.embed_query(\"Vaish's mother is a teacher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7806410337241658, 0.39281267505323264)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "query_sentence1_similarity = cosine_similarity([embedded_query], [sentence1])[0][0]\n",
    "query_sentence2_similarity = cosine_similarity([embedded_query], [sentence2])[0][0]\n",
    "\n",
    "query_sentence1_similarity, query_sentence2_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "\n",
    "vectorstore1 = DocArrayInMemorySearch.from_texts(\n",
    "    [\n",
    "        \"Mary's sister is Susana\",\n",
    "        \"John and Tommy are brothers\",\n",
    "        \"Patricia likes white cars\",\n",
    "        \"Pedro's mother is a teacher\",\n",
    "        \"Lucia drives an Audi\",\n",
    "        \"Mary has two siblings\",\n",
    "    ],\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={}, page_content=\"Mary's sister is Susana\"),\n",
       "  0.7440929421471949),\n",
       " (Document(metadata={}, page_content='Mary has two siblings'),\n",
       "  0.7013327194745267),\n",
       " (Document(metadata={}, page_content='John and Tommy are brothers'),\n",
       "  0.5149859044829919)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore1.similarity_search_with_score(query=\"Who is Mary's sister?\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content=\"Mary's sister is Susana\"),\n",
       " Document(metadata={}, page_content='Mary has two siblings'),\n",
       " Document(metadata={}, page_content='John and Tommy are brothers'),\n",
       " Document(metadata={}, page_content='Patricia likes white cars')]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever1 = vectorstore1.as_retriever()\n",
    "retriever1.invoke(\"Who is Mary's sister?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [Document(metadata={}, page_content='Patricia likes white cars'),\n",
       "  Document(metadata={}, page_content='Lucia drives an Audi'),\n",
       "  Document(metadata={}, page_content=\"Pedro's mother is a teacher\"),\n",
       "  Document(metadata={}, page_content=\"Mary's sister is Susana\")],\n",
       " 'question': \"What color is Patricia's car?\"}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "setup = RunnableParallel(context=retriever1, question=RunnablePassthrough())\n",
    "setup.invoke(\"What color is Patricia's car?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'white'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = setup | prompt | gemini_model | parser\n",
    "chain.invoke(\"What color is Patricia's car?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lucia drives an Audi.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What car does Lucia drive?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore2 = DocArrayInMemorySearch.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"AI agents must reason and act. A key trait of AI agents is their ability to iterate. The one massive change that has to happen in order for an AI workflow to become an AI agent is for the human decision maker to be replaced by an LLM. In other words, the AI agent must reason what's the most efficient way to compile these news articles.\""
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = (\n",
    "    {\"context\": vectorstore2.as_retriever(), \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | gemini_model\n",
    "    | parser\n",
    ")\n",
    "chain.invoke(\"What is AI Agents?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "index_name = \"rag2\"\n",
    "\n",
    "pinecone = PineconeVectorStore.from_documents(\n",
    "    documents, embeddings, index_name=index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'transcript.txt'}, page_content=\"drafted V1 of a LinkedIn post how do I make sure it's good oh I know i'll add another step where an LM will critique the post based on LinkedIn best practices and let's repeat this until the best practices criteria are all met and after a few cycles of that we have the final output that was a hypothetical example so let's move on to a real world AI agent example andrew is a preeeminent figure in AI and he created this demo website that illustrates how an AI agent works i'll link the full video down below but when I search for a keyword like skier enter the AI vision agent in the background is first reasoning what a skier looks like a person on skis going really fast in snow for example right i'm not sure and then it's acting by looking at clips in video footage trying to identify what it thinks a skier is indexing that clip and then returning that clip to us although this might not feel impressive remember that an AI agent did all that instead of a human reviewing the footage\"),\n",
       " Document(metadata={'source': 'transcript.txt'}, page_content=\"ai ai ai ai ai ai you know more agentic agentic capabilities an AI agent agents agentic workflows agents agents agent agent agent agent agentic all right most explanations of AI agents is either too technical or too basic this video is meant for people like myself you have zero technical background but you use AI tools regularly and you want to learn just enough about AI agents to see how it affects you in this video we'll follow a simple one two three learning path by building on concepts you already understand like chatbt and then moving on to AI workflows and then finally AI agents all the while using examples you will actually encounter in real life and believe me when I tell you those intimidating terms you see everywhere like rag rag or react they're a lot simpler than you think let's get started kicking things off at level one large language models popular AI chatbots like CHBT Google Gemini and Claude are applications built on top of large language models LLMs and they're\"),\n",
       " Document(metadata={'source': 'transcript.txt'}, page_content=\"forward all right level three AI agents continuing the make.com example let's break down what I've been doing so far as the human decision maker with the goal of creating social media posts based off of news articles I need to do two things first reason or think about the best approach i need to first compile the news articles then summarize them then write the final posts second take action using tools i need to find and link to those news articles in Google Sheets use Perplexity for real-time summarization and then claw for copyrightiting so and this is the most important sentence in this entire video the one massive change that has to happen in order for this AI workflow to become an AI agent is for me the human decision maker to be replaced by an LLM in other words the AI agent must reason what's the most efficient way to compile these news articles should I copy and paste each article into a word document no it's probably easier to compile links to those articles and then use\")]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone.similarity_search(\"Real life example of AI agents?\")[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Andrew created a demo website that illustrates how an AI agent works. When a keyword like \"skier\" is entered, the AI vision agent reasons what a skier looks like and then acts by looking at clips in video footage to identify what it thinks a skier is, indexing that clip, and then returning that clip to us.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = (\n",
    "    {\"context\": pinecone.as_retriever(), \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | gemini_model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "chain.invoke(\"Real life example of AI agents?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
